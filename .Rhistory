data %>%
ggvis(~Date, ~Value) %>%
layer_points() %>%
layer_lines() %>%
layer_model_predictions(model="lm", stroke:="red",
domain=input_select(
c(as.Date(c("2014-01-03","2015-12-23")),
as.Date(c("2014-01-03","2016-04-23")),
as.Date(c("2014-01-03","2016-12-23")),
as.Date(c("2014-01-03","2017-04-23"))
), selected = as.Date(c("2014-01-03","2015-12-23")),map = as.Date))
o1<-as.Date(c("2014-01-03","2015-12-23"))
o2<-as.Date(c("2014-01-03","2016-04-23"))
o3<-as.Date(c("2014-01-03","2016-12-23"))
o4<-as.Date(c("2014-01-03","2017-04-23"))
data %>%
ggvis(~Date, ~Value) %>%
layer_points() %>%
layer_lines() %>%
layer_model_predictions(model="lm", stroke:="red",
domain=input_select(c(o1,o2,o3,o4),
selected = o1, map = as.Date))
data %>%
ggvis(~Date, ~Value) %>%
layer_points() %>%
layer_lines() %>%
layer_model_predictions(model="lm", stroke:="red",
domain=input_radiobuttons(c(o1,o2,o3,o4),
selected = o1))
data %>%
ggvis(~Date, ~Value) %>%
layer_points() %>%
layer_lines() %>%
layer_model_predictions(model="lm", stroke:="red",
domain=input_radiobuttons(c(o1,o2,o3,o4),
selected = o1, map=as.Date))
data %>%
ggvis(~Date, ~Value) %>%
layer_points() %>%
layer_lines() %>%
layer_model_predictions(model="lm", stroke:="red",
domain=input_radiobuttons(c(o1,o2,o3,o4), map=as.Date))
data %>%
ggvis(~Date, ~Value) %>%
layer_points() %>%
layer_lines() %>%
layer_model_predictions(model="lm", stroke:="red",
domain=input_radiobuttons(c(o1,o2,o3,o4),
selected=as.Date(c("2014-01-03","2015-12-23")), map=as.Date))
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mean(w)
mean(x)
mean(w*x)
mean(x*w)
mean(x+w)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit <- lm(y ~ x)
summary(fit)
fit
fit$slope
?lm
data(mtcars)
library(datasets)
data(mtcars)
fit <- lm(mpg ~ weight, data=mtcars)
fit <- lm(mpg ~ weight, data=mtcars)
names(mtcars)
fit <- lm(mpg ~ wt, data=mtcars)
summary(fit)
fit <- lm(y ~ x - 1)
summary(fit)
0.4*1.5
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
?normalize
?z
?norm
scale(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit <- lm(y ~ x)
summary(fit)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mean(x,w)
mean(c(x,w))
mean(w)
mean(x+w)
mean(w-x)
rnorm(2)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("AppliedPredictiveModeling", "caret")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
install.packages("caret")
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
str(train$CompressiveStrength)
str(train)
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
str(training$CompressiveStrength)
plot(train$CompressiveStrength,pch=19)
plot(training$CompressiveStrength,pch=19)
?cut2
install.packages("Hmisc")
library(Hmisc)
?cut2
str(training)
qplot(training$CompressiveStrength,pch=19)
qplot(training$CompressiveStrength,geom="point",pch=19)
qplot(training$CompressiveStrength,geom="point")
qplot(training$CompressiveStrength,geom="points")
qplot(data=training,CompressiveStrength, geom="points")
qplot(data=training,CompressiveStrength, geom="point")
args(qplot)
qplot(data=training,CompressiveStrength)
qplot(data=training,y=CompressiveStrength, x=c(1:length(trainig)))
qplot(data=training,y=CompressiveStrength, x=c(1:length(training)))
qplot(data=training,y=CompressiveStrength, x=c(0:length(training)))
qplot(data=training,y=CompressiveStrength, x=c(1:length(training)-1))
qplot(data=training,y=CompressiveStrength, x=c(1:length(CompressiveStrength)-1))
ssiveStrength,
x=c(1:length(CompressiveStrength)-1),
color=cut2(training[,.]))
cut2(training[,.]
)
cut2(training[.])
cut2(training)
names$training
names(training)
iveStrength,
x=c(1:length(CompressiveStrength)-1),
color=cut2(training$Cement))
qplot(data=training,y=CompressiveStrength,
x=c(1:length(CompressiveStrength)-1),
color=cut2(training$Cement))
qplot(data=training,y=CompressiveStrength,
x=c(1:length(CompressiveStrength)-1),
color=cut2(training$BlastFurnaceSlag))
color=cut2(training$FlyAsh))
qplot(data=training,y=CompressiveStrength,
x=c(1:length(CompressiveStrength)-1),
color=cut2(training$FlyAsh))
qplot(data=training,y=CompressiveStrength,
x=c(1:length(CompressiveStrength)-1),
color=cut2(training$Water))
qplot(data=training,y=CompressiveStrength,
x=c(1:length(CompressiveStrength)-1),
color=cut2(training$Superplasticizer))
qplot(data=training,y=CompressiveStrength,
x=c(1:length(CompressiveStrength)-1),
color=cut2(training$CoarseAggregate))
qplot(data=training,y=CompressiveStrength,
x=c(1:length(CompressiveStrength)-1),
color=cut2(training$FineAggregate))
qplot(data=training,y=CompressiveStrength,
x=c(1:length(CompressiveStrength)-1),
color=cut2(training$Age))
qplot(data=training,y=CompressiveStrength,
x=c(1:length(CompressiveStrength)-1),
color=cut2(training$CompressiveStrength))
qplot(data=training,y=CompressiveStrength)
qplot(data=training,CompressiveStrength)
qplot(data=training,SuperPlasticizer )
qplot(data=training,SuperPlasticizer)
qplot(data=training, Superplasticizer)
qplot(data=training, log(Superplasticizer))
summary(Superplasticizer)
summary(training$Superplasticizer)
qplot(data=training, log(Superplasticizer+1))
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(dplyr)
?dplyr
x <- training %>%
select(starts("IL"))
x <- training %>%
select(starts_with("IL"))
x
?preProcess
preX <- preProcess(x, method="pca")
summary(preX)
preX
preX <- preProcess(x, method="pca", thresh=0.8)
preX
names(training)
x <- training %>%
select(starts_with("IL"),diagnosis)
preX <- preProcess(x, method="pca", thresh=0.8)
preX <- preProcess(x[-diagnosis], method="pca", thresh=0.8)
preX <- preProcess(x[,-diagnosis], method="pca", thresh=0.8)
preX <- preProcess(x[,-1], method="pca", thresh=0.8)
names(x)
preX <- preProcess(x[,-13], method="pca", thresh=0.8)
?train
model1 <- train(diagnosis ~ ., data=x, method="glm")
install.packages("e1071")
model1 <- train(diagnosis ~ ., data=x, method="glm")
model2 <- train(diagnosis ~ ., data=preX, method="glm")
model2 <- train(diagnosis ~ ., data=x, preProcess=preX, method="glm")
model2 <- train(diagnosis ~ ., data=x, preX, method="glm")
model2 <- predict(preX, x[,-13])
model1
model2
predata <- train(preX, x[,-13])
model2 <- train(diagnosis ~ ., data=predata, method="glm")
predata <- train(preX, x[,-13])
predata <- predict(preX, x[,-13])
model33 <- train(diagnosis ~ ., data=predata, method="glm")
predata$diagnosis <- x$diagnosis
model33 <- train(diagnosis ~ ., data=predata, method="glm")
model33
round(0.6921324, 2)
model1
round(0.6873802, 2)
x <- training %>%
select(starts_with("IL"),diagnosis)
preX <- preProcess(x[,-13], method="pca", thresh=0.8)
prex
preX
preX <- preProcess(x[,-13], method="pca", thresh=0.9)
preX
?geom_jitter
library(swirl)
install.packages("swirl")
library(swirl)
install_from_swirl("Regression Models")
install_from_swirl("Regression Models")
swirl
swirl()
install_from_swirl("Regression Models")
swirl()
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent -1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
View(trees)
fit <- lm(Volume ~ Girth + Height + Constant -1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant - 1, trees2)
lapply(list(fit, fit2), coef)
all <- lm(Fertility ~ ., swiss)
summary(all)
summary(lm(Fertility ~ Agriculture, swicc))
summary(lm(Fertility ~ Agriculture, swiss))
cor(Examination ~ Education, swiss)
cor(swiss$Examination, swiss$Education)
cor(swiss$Agriculture, swiss$Education)
makelms()
ec <- swiss$Examination + swiss$Catholic
lm(Fertility ~ . + ec, swiss)
efin <- lm(Fertility ~ . + ec, swiss)
efit <- lm(Fertility ~ . + ec, swiss)
coef(fit) - coef(efit)
all$coefficients-efit$coefficients
6
dim(InsectSpray)
dim(InsectSprays)
head(InsectSprays)
head(InsectSprays, 15)
sA
summary(InsectSprays[,2])
sapply(InsectSprays[,2], class)
sapply(InsectSprays, class)
lm(count ~ spray, InsectSprays)
fit <- lm(count ~ spray, InsectSprays)
summary(fit)
summary(fit)$coef
est <- summary(fit)$coef[,1]
mean(xA)
mean(sA)
mean(sB)
nfit <- lm(count ~ spray - 1, InsectSprays)
summary(nfit)$coef
spray2 <- relevel(InsectSprays$spray, "C")
fit2 <- lm(count ~ spay2, InsectSprays)
fit2 <- lm(InsectSprays$count ~ spay2)
fit2 <- lm(count ~ spray2, InsectSprays)
summary(fit2)$coef
mean(sC)
fit$coef[2] - fit$coef[3]
(fit$coef[2] - fit$coef[3])/1.6011
library(swirl)
swirl()
dim(hunger)
948
names(hunger)
fit <- lm(Numeric ~ Year, hunger)
summary(fit)$coef
lmF <- lm(Numeric ~ Year,hunger[hunger$Sex=="Female"])
lmF <- lm(Numeric ~ Year,hunger[,hunger$Sex=="Female"])
lmF <- lm(Numeric ~ Year,hunger[hunger$Sex=="Female",])
lmF <- lm(hunger$Numeric[hunger$Sex=="Female"]
)
lmF <- lm(hunger$Numeric[hunger$Sex=="Female"])
lmF <- lm(Numeric[Sex=="Female"] ~ Year[Sex=="Female"],hunger)
lmM <- lm(Numeric[Sex=="Male"] ~ Year[Sex=="Male"],hunger)
lmBoth <- lm(Numeric ~ Year + Sex,hunger)
summary(lmBoth)
lmInter <- lm(Numeric ~ Year + Sex + Sex*Year, hunger)
summary(lmI)
summary(lmInter)
fit <- lm(y ~ x, out2)
plot(fit, which=1)
fitno <- lm(y ~ x, out2[-1,])
plot(fitno, which=1)
coef(fit)-coef(fitno)
View(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
hatvalues(fit)
head(hatvalues(fit))
sigma <- sqrt(coef(fit)/deviance(coef(fit)))
fit$sigma
summary(fit)$sigma
sigma <- sqrt(deviance(fit)/df.residual(fit))
rstd <- sigma*sqrt(1-hatvalues(fit))
rstd <- resid(fit)/(sigma * sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which=3)
plot(fit, which=2)
sigma1 <- sqrt(deviance(fitno)/df.residual(fitno))
resid(fit)[1] / (sigma1 + sqrt(1-hatvalues(fit)[1]))
resid(fit)[1] / (sigma1 sqrt(1-hatvalues(fit)[1]))
resid(fit)[1] / (sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
dy <- predict(fitno, out2) - predict(fit, out2)
dy / 2*sigma^2
sum(dy^2)/(2*sigma^2)
plot(fit, which=5)
rgp1()
rgp2()
head(swiss)
mdl <- (Fertility ~ ., swiss)
mdl <- lm(Fertility ~ ., swiss)
vif(mdl)
mdl <- lm(Fertility ~ ., swiss[-Examination,])
mdl <- lm(Fertility ~ ., swiss[-Examination])
mdl <- lm(Fertility ~ ., swiss[-3,])
mdl2 <- lm(Fertility ~ ., swiss[-3,])
mdl2 <- lm(Fertility ~ . -Examination, swiss)
vif(mdl2)
simbias()
x1c <- simbias()
apply(x1c,1,mean)
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1) - deviance(fit3)) /2
n/d
pf(n/d, 2,43, lower.tail=F)
pf(n/d, 2,43, lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.test)
vowel.test$y <- factor(vowel.test$y)
vowel.train$y <- factor(vowel.train$y)
library(caret)
rfit <- train(y~., data=vowel.train, method="rf")
gbmfit <- train(y~., data=vowel.train, method="gbm")
summary(rfit)
rfit
gbmfit
Predictions1 <- predict(rfit, newdata=vowel.test[,-1])
confMatrix <- confusionMatrix(Predictions1, vowel.test$y)
confMatrix
Predictions2 <- predict(gbmfit, newdata=vowel.test[,-1])
confMatrix <- confusionMatrix(Predictions2, vowel.test$y)
confMatrix
?set.seed
get.seed()
set.seed(33833)
rfit <- train(y~., data=vowel.train, method="rf")
Predictions1 <- predict(rfit, newdata=vowel.test[,-1])
confMatrix <- confusionMatrix(Predictions1, vowel.test$y)
confMatrix
install.packages("likert")
install.packages("Cairo")
install.packages("likert")
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
w*(x-mean(x))^2
sum(w*(x-mean(x))^2)
x
x-mean(x)
mean(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
model <- lm(y~x - 1)
model
data(mtcars)
model <- lm(mpg ~ weight, data=mtcars)
model <- lm(mpg ~ wt, data=mtcars)
model
data(galton)
library(UsingR)
install.packages("UsingR")
library(UsingR)
data(galton)
1.5*0.4
?normalize
c <- (x - mean(x))/sd(x)
c[1]
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
c <- (x - mean(x))/sd(x)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
c <- (x - mean(x))/sd(x)
c[1]
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
x <- c(0.18, -1.54, 0.42, 0.95)
mean(x)
w*mean(x)
mean(x*w)
w
sum(mean(x)*w)
sum(w*mean(x))
sum(mean(w)*mean(x))
sum(mean(x))
w
mean(w)
mean(w)+mean(x)
mean(w)-mean(x)
lm(w~x)
sum(w*x)/sum(w)
model <- lm(y~x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
model <- lm(y~x)
model
coef(model)[2]
coef(lm(x~y))[2]
coef(model)[2]/coef(lm(x~y))[2]
var(y)/var(x)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
summary(lm(y ~ x))
sd(resid(lm(y ~ x)))
?sd
data(mtcars)
fit <- lm(mpg ~ wt, data=mtcars)
?ci
?CI
?predict
predict(fit, "prediction")
predict(fit, interval="prediction")
predict(fit, interval="confidence")
?mtars
?mtcars
predict(fit, newdata=data.frame(wt=3000) interval="confidence")
predict(fit, newdata=data.frame(wt=3000), interval="confidence")
predict(fit, newdata=data.frame(wt=3000/1000), interval="confidence")
predict(fit, newdata=data.frame(wt=3000/1000), interval="prediction")
predict(fit, newdata=data.frame(wt=wt/1000), interval="confidence")
predict(fit, newdata=data.frame(wt=mtcars$wt/1000), interval="confidence")
summary(lm(mpg ~ wt, data = mtcars))
summary(lm(mpg ~ wt - 1, data = mtcars))
0.7528 / 0.7197
-9.559 / 8.921
summary(lm(mpg ~ wt - 1, data = mtcars))$
$
summary(lm(mpg ~ wt - 1, data = mtcars))$predicted
names(summary(lm(mpg ~ wt - 1, data = mtcars)))
yhat <- predict(fit)
yhat <- predict(lm(mpg ~ wt - 1, data = mtcars))
yhat <- predict(fit)
yhat1 <- predict(lm(mpg ~ wt - 1, data = mtcars))
yhat/yhat1
sum(mpg - yhat)^2
sum(mtcarsmpg - yhat)^2
sum(mtcars$mpg - yhat)^2
sum(mtcars$mpg - yhat1)^2
sum(mtcars$mpg - yhat)^2 / sum(mtcars$mpg - yhat1)^2
sum((mtcars$mpg - yhat)^2) / sum((mtcars$mpg - yhat1)^2)
setwd("~/mpg-app/pitch-presentation")
publish("mpg-app-presentation", "pased")
library(slidify)
publish("mpg-app-presentation", "pased")
